{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Machine Learning Algorithms Consistently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a myriad of metrics that can be used to evaluate predictions by classification problems. Some mostly useful are listed below:\n",
    "\n",
    " Classification Accuracy:Classification accuracy is the number of correct predictions made as a ratio of all predictions made.It is really only suitable when there are an equal number of observations in each class (which is rarely the case) and that all predictions and prediction errors are equally important, which is often not the case. \n",
    "\n",
    " Logarithmic Loss:Logarithmic loss (or logloss) is a performance metric for evaluating the predictions of probabilities of membership to a given class. The scalar probability between 0 and 1 can be seen as a measure of confidence for a prediction by an algorithm.\n",
    "\n",
    " Area Under ROC Curve:Area under ROC Curve (or AUC for short) is a performance metric for binary classification problems. The AUC represents a model’s ability to discriminate between positive and negative classes. An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model that is as good as random.\n",
    "\n",
    " Confusion Matrix:The confusion matrix is a handy presentation of the accuracy of a model with two or more classes.\n",
    "\n",
    " Classification Report:The scikit-learn library provides a convenience report when working on classification problems to give you a quick idea of the accuracy of a model using a number of measures. The classification report() function displays the precision, recall, F1-score and support for each class. \n",
    "\n",
    "In the next section we will discover exactly how we compare machine learning algorithms consistency in Python with scikit-learn. To compare the machine learning algorithms let's evaluate each classification algorithm in same way on same dataset.The dataset is the Pima Indians onset of diabetes problem. The problem has two classes and eight numeric input variables of varying scales. The 10-fold cross validation procedure is used to evaluate six different classification algorithm, importantly configured with the same random seed to ensure that the same splits to the training data are performed and that each algorithm is evaluated in precisely the same way. Each algorithm is given a short name, useful for summarizing results afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.772163 (0.049684)\n",
      "LDA: 0.766969 (0.047966)\n",
      "KNN: 0.710988 (0.050792)\n",
      "CART: 0.696753 (0.052264)\n",
      "NB: 0.759142 (0.038960)\n",
      "SVM: 0.760458 (0.034712)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYx0lEQVR4nO3dfZQcVZ3G8e/jSJJVIM5sokheSNTABqMEHXEVVLII5qAroi4k4ho4kbiuoCe4rmg4S4gbRc8qvgUVDeIbE5AVNu7qAruAEgXNRLNIwluIYMaIBjIQkLck/PaPqoZKp2emZ6anX+48n3P6pKtuVde93ZOnq29V3VJEYGZm6XpWoytgZmYjy0FvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B70NiqRLJP3rCL32KZKu6af8aEk9I7HtVifp45K+0eh6WHNy0FtFkm6Q1CtpbL22GRHfi4jjCnUISS+p1/aV+aCkWyX9WVKPpO9Lelm96jBUEfHJiHhvo+thzclBb3uRNA14HRDAW+u0zWfXYzsD+ALwIeCDQAdwMHAV8OZGVmogTfLeWRNz0Fsl7wFuBi4BFvS3oKR/lvQHSVslvbe4Fy5pvKRvS9om6V5J50h6Vl52qqSfSbpA0nZgaT5vTV7+03wT/yfpEUknF7b5YUl/yrd7WmH+JZIulPTjfJ2fSTpA0ufzXye3Szq8j3bMAD4AzI+I6yLiiYh4NP+Vcf4g2/OgpM2SXpvP35LXd0FZXb8q6VpJD0v6iaSDCuVfyNfbIWmdpNcVypZKukLSdyXtAE7N5303Lx+Xlz2Q12WtpBfkZQdKWi1pu6RNkk4ve93L8zY+LGmDpM7+Pn9rDQ56q+Q9wPfyx5tKIVFO0lzgLOCNwEuAN5Qt8iVgPPCivOw9wGmF8lcDm4HnA8uLK0bE6/Onh0XEvhFxWT59QP6ak4CFwApJ7YVVTwLOASYATwA3Ab/Kp68APtdHm48BeiLil32UV9ueW4C/BC4FVgGvIntv3g18WdK+heVPAT6R12092ftdshaYTfbL4lLg+5LGFcpPyNvzvLL1IPtyHg9MyevyD8BjeVkX0AMcCLwT+KSkYwrrvjWv9/OA1cCX+3k/rEU46G0Pko4CDgIuj4h1wN3Au/pY/CTgmxGxISIeBc4rvE4bcDLwsYh4OCLuAT4L/H1h/a0R8aWI2BURj1GdncCyiNgZET8CHgEOKZRfGRHrIuJx4Erg8Yj4dkTsBi4DKu7RkwXiH/raaJXt+W1EfLOwrSl5XZ+IiGuAJ8lCv+S/IuKnEfEEsAR4jaQpABHx3Yh4IH9vPguMLWvnTRFxVUQ8VeG925m35yURsTt/P3bkr30U8NGIeDwi1gPfKGvDmoj4Ud6G7wCH9fWeWOtw0Fu5BcA1EXF/Pn0pfXffHAhsKUwXn08AxgD3FubdS7YnXmn5aj0QEbsK048Cxb3kPxaeP1ZhurjsHq8LvLCf7VbTnvJtERH9bf/p9kfEI8B2sve01D11m6SHJD1Itoc+odK6FXwHuBpYlXepfUbSPvlrb4+Ih/tpw32F548C43wMoPU56O1pkv6CbC/9DZLuk3QfsBg4TFKlPbs/AJML01MKz+8n27M8qDBvKvD7wnQzDZ36v8Dkfvqkq2nPYD39fuVdOh3A1rw//qNkn0V7RDwPeAhQYd0+37v81855EXEo8FrgLWTdTFuBDkn71bAN1gIc9Fb0NmA3cChZ//BsYCZwI1lQlLscOE3STEnPAf6lVJD/9L8cWC5pv/xA41nAdwdRnz+S9YePuIi4C7gQ6FJ2vv6Y/KDmPEln16g95Y6XdJSkMWR99b+IiC3AfsAuYBvwbEn/Auxf7YtKmiPpZXl30w6yL6jd+Wv/HPhU3raXkx3nKO/jt8Q46K1oAVmf++8i4r7Sg+yA3CnlP+Ej4sfAF4HrgU1kBz4hOwgKcCbwZ7IDrmvIuoEuHkR9lgLfys8cOWmIbRqMD5K1dQXwINnxiROBH+blw21PuUuBc8m6bF5JdnAWsm6XHwN3knWtPM7gurkOIDtQuwO4DfgJz3whzQemke3dXwmcGxHXDqMN1gLkG49YrUiaCdwKjC3rR7cyki4hO8vnnEbXxdLnPXobFkkn5t0c7cCngR865M2ai4Pehut9ZH3Jd5P177+/sdUxs3LuujEzS5z36M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLXNPd3X3ChAkxbdq0RlfDzKylrFu37v6ImFiprOmCftq0aXR3dze6GmZmLUXSvX2VuevGzCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLXNNdMDUSJA153YioYU3MzOpvVAR9f2EtyWFuZkkbFUGfOv9iMbP+OOgT4F8sZtYfH4w1M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxCVzz9iOjg56e3uHtO5Qbq7d3t7O9u3bh7Q9s9HEN69vvGSCvre3t65/FMP54zUbTXzz+sarqutG0lxJd0jaJOnsCuVTJV0v6deSbpF0fKHsY/l6d0h6Uy0rb2ZmAxtwj15SG7ACOBboAdZKWh0RGwuLnQNcHhFfkXQo8CNgWv58HvBS4EDgfyQdHBG7a92Q1Llryqz5tEq3VDVdN0cAmyJiM4CkVcAJQDHoA9g/fz4e2Jo/PwFYFRFPAL+VtCl/vZtqUPdRxV1TZs2nVbqlqum6mQRsKUz35POKlgLvltRDtjd/5iDWRdIiSd2Surdt21Zl1c2sWXR0dCBp0A9gSOt1dHQ0uMWtpZqgr7RrV/41NR+4JCImA8cD35H0rCrXJSIuiojOiOicOHFiFVUys2ZS+sVZr8dQuzFHq2q6bnqAKYXpyTzTNVOyEJgLEBE3SRoHTKhyXTMzG0HV7NGvBWZImi5pDNnB1dVly/wOOAZA0kxgHLAtX26epLGSpgMzgF/WqvJmZjawAffoI2KXpDOAq4E24OKI2CBpGdAdEauBDwNfl7SYrGvm1MiOQmyQdDnZgdtdwAd8xo2ZWX2pWY4Kl3R2dkZ3d/eg16v3EW5vz+wZ/vvcWwPek3UR0VmpzGPdmJklzkFvZpY4B72ZWeIc9GZmiUtm9EpLV6uMJ2JpSmGcKQe9Nb1WGU/E0pTCOFPuujEzS1wye/Rx7v6wdHx9t1dHqbfPzEaOL5gaIm+vObRKPVOX8t9nq7TNF0yZmY1iDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEpfMjUfMWpXvidvcUrjpj4PerMF8T9zmpvN21P/GI0tr+5ruujEzS5yD3swscQ56M7PEOejNzBLng7FmNmwpnJmSMge9mQ1bCmempMxdN2ZmiXPQm5klzkFvZpY4B72ZWeKqCnpJcyXdIWmTpLMrlF8gaX3+uFPSg4Wy3YWy1bWsvJmZDWzAs24ktQErgGOBHmCtpNURsbG0TEQsLix/JnB44SUei4jZtauymZkNRjWnVx4BbIqIzQCSVgEnABv7WH4+cG5tqmdm1njDGWF0sNrb22v+mtUE/SRgS2G6B3h1pQUlHQRMB64rzB4nqRvYBZwfEVdVWG8RsAhg6tSp1dXczKwOhnp9QDONPFpNH32lr7K+aj8PuCIidhfmTY2ITuBdwOclvXivF4u4KCI6I6Jz4sSJVVTJzMyqVU3Q9wBTCtOTga19LDsP6CrOiIit+b+bgRvYs//ezMxGWDVBvxaYIWm6pDFkYb7X2TOSDgHagZsK89oljc2fTwCOpO++fTMzGwED9tFHxC5JZwBXA23AxRGxQdIyoDsiSqE/H1gVe3ZKzQS+Jukpsi+V84tn65iZ2chTsxwsKOns7Izu7u5Br1fvAx/eXnNolXoOVau0z3+fe2vAe7IuPx66F18Za2aWOAe9mVniPB59C2n1izbMrDGSCvqUgzCFizZGs46ODnp7e4e07lD+rtvb29m+ffuQtmfpSSboHYTWzHp7e+t+sNKsxH30ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9BbU+jo6EDSoB/AkNbr6OhocIvN6ieZIRCstXmIALOR4z16M7PEOejNzBLnoDczS5yD3swscT4Ya00hzt0flo6v7/bMRgkHvTUFnbej7mfdxNK6bW5USPkOb63OQW9mw+Y7vDU399GbmSXOQW9mljgHvZlZ4txHb2Y2RAMdgO6vvJ7HJhz0ZmZD1CoHkt11Y2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZomrKuglzZV0h6RNks6uUH6BpPX5405JDxbKFki6K38sqGXlzcxsYANeMCWpDVgBHAv0AGslrY6IjaVlImJxYfkzgcPz5x3AuUAnEMC6fN3emrbCzMz6VM0e/RHApojYHBFPAquAE/pZfj7QlT9/E3BtRGzPw/1aYO5wKmxmZoNTzRAIk4Atheke4NWVFpR0EDAduK6fdScNvppm1qpaZTyYlFUT9JU+hb7e/XnAFRGxezDrSloELAKYOnVqFVUys1bhsG68arpueoAphenJwNY+lp3HM902Va8bERdFRGdEdE6cOLGKKpmZWbWqCfq1wAxJ0yWNIQvz1eULSToEaAduKsy+GjhOUrukduC4fJ6ZmdXJgF03EbFL0hlkAd0GXBwRGyQtA7ojohT684FVUfidFhHbJX2C7MsCYFlEbK9tE8zMrD9qtv6zzs7O6O7urtv2Ur85cau0r971rPv7snR8/bb19DYfqv82rWEkrYuIzkplvvGIWR3ovB31/yJbWrfNWZPzEAhmZolz0JuZ1VBXVxezZs2ira2NWbNm0dXVNfBKI8xdN2ZmNdLV1cWSJUtYuXIlRx11FGvWrGHhwoUAzJ8/v2H18h69mVmNLF++nJUrVzJnzhz22Wcf5syZw8qVK1m+fHlD6+WzblrkrJShapX2pX7WTerbs0xbWxuPP/44++yzz9Pzdu7cybhx49i9e3c/aw5ff2fdeI/ezKxGZs6cyZo1a/aYt2bNGmbOnNmgGmUc9GZmNbJkyRIWLlzI9ddfz86dO7n++utZuHAhS5YsaWi9fDDWzKxGSgdczzzzTG677TZmzpzJ8uXLG3ogFtxHn3xfZqu0L/U+7NS3Z43nPnozs1HMQW9mljgHvZlZ4hz0ZmaJ81k31jQGurdoLbW3t9dtW2aN5qC3pjDUM0R8donZwNx1Y2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJW5UDGo20KiI/ZW3woBZqbfPzIZnVAR96mGWevvMbHjcdWNmljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4qoKeklzJd0haZOks/tY5iRJGyVtkHRpYf5uSevzx+paVdzMzKoz4Hn0ktqAFcCxQA+wVtLqiNhYWGYG8DHgyIjolfT8wks8FhGza1xvMzOrUjV79EcAmyJic0Q8CawCTihb5nRgRUT0AkTEn2pbTTMzG6pqgn4SsKUw3ZPPKzoYOFjSzyTdLGluoWycpO58/tsqbUDSonyZ7m3btg2qAWZm1r9qhkCoNFBK+TX3zwZmAEcDk4EbJc2KiAeBqRGxVdKLgOsk/SYi7t7jxSIuAi4C6Ozs9PX8lqSBxiSqpfb29rpty5pfNUHfA0wpTE8GtlZY5uaI2An8VtIdZMG/NiK2AkTEZkk3AIcDd2M2igx1PCJJHsvIhq2arpu1wAxJ0yWNAeYB5WfPXAXMAZA0gawrZ7OkdkljC/OPBDZiZmZ1M+AefUTsknQGcDXQBlwcERskLQO6I2J1XnacpI3AbuAjEfGApNcCX5P0FNmXyvnFs3XMzGzkqdl+FnZ2dkZ3d3ejq2EtIvWujdTbZ7UjaV1EdFYq85WxZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSVuwHvGmtnIkjTkct9m0KrhoDdrMIe1jTR33ZiZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOA+BYE3PY8GYDY+D3pqew9pseNx1Y2aWOAe9mVniHPRmZolz0JuZJa6qoJc0V9IdkjZJOruPZU6StFHSBkmXFuYvkHRX/lhQq4qbmVl1BjzrRlIbsAI4FugB1kpaHREbC8vMAD4GHBkRvZKen8/vAM4FOoEA1uXr9ta+KWZmVkk1e/RHAJsiYnNEPAmsAk4oW+Z0YEUpwCPiT/n8NwHXRsT2vOxaYG5tqm5mZtWoJugnAVsK0z35vKKDgYMl/UzSzZLmDmJdJC2S1C2pe9u2bdXX3szMBlTNBVOVLjssv4Ll2cAM4GhgMnCjpFlVrktEXARcBCBpm6R7q6hXrUwA7q/j9urN7Wttbl/rqnfbDuqroJqg7wGmFKYnA1srLHNzROwEfivpDrLg7yEL/+K6N/S3sYiYWEWdakZSd0R01nOb9eT2tTa3r3U1U9uq6bpZC8yQNF3SGGAesLpsmauAOQCSJpB15WwGrgaOk9QuqR04Lp9nZmZ1MuAefUTsknQGWUC3ARdHxAZJy4DuiFjNM4G+EdgNfCQiHgCQ9AmyLwuAZRGxfSQaYmZmlWm0DxglaVF+jCBJbl9rc/taVzO1bdQHvZlZ6jwEgplZ4kZV0Et6pMK8pZJ+L2l9PoTD/EbUbSiqaM9dkn4g6dCyZSZK2inpffWr7eAU2ybp+LwtU/P2PVq6+rrCsiHps4Xpf5K0tG4VH4CkAyStknR3/vf2I0kH52WLJT0uaXxh+aMlPSTp15Jul/Rv+fzT8s94vaQnJf0mf35+o9rWl/4+k7K/19slfUVS0+eSpCX5cC+35HX/saRPlS0zW9Jt+fN7JN1YVr5e0q31qG/Tv6F1ckFEzCa74vdrkvZpdIWG6YKImB0RM4DLgOskFU9b/TvgZqDpv9QkHQN8CZgbEb/LZ98PfLiPVZ4A3p6f/dVUlN0K60rghoh4cUQcCnwceEG+yHyyExdOLFv1xog4HDgceIukIyPim/lnPJvsdOc5+XTFsagabKDPpPT/71DgZcAb6lazIZD0GuAtwCsi4uXAG4HzgZPLFp0HXFqY3k/SlPw1ZtajriUO+oKIuAt4FGhvdF1qJSIuA64B3lWYPZ8sKCdL2utK5WYh6XXA14E3R8TdhaKLgZPzsZTK7SK7+G5xHao4WHOAnRHx1dKMiFgfETdKejGwL3AOfXwBR8RjwHoqXF3e5Kr9TMYA44BmHwvrhcD9EfEEQETcHxE/AR6U9OrCcieRDRlTcjnPfBnMB7rqUVlw0O9B0iuAuwpj9aTiV8BfAeR7FAdExC/Z8w+v2YwF/gN4W0TcXlb2CFnYf6iPdVcApxS7QJrELGBdH2Wl//g3AocUu6ZK8mtRZgA/HbEajpz+PpPFktYDfwDujIj19a3aoF0DTJF0p6QLJZV+gXSR7cUj6a+BB/Kdx5IrgLfnz/8W+GG9KuygzyzOr+b9BbC0wXUZCcWhKOaRBTxkexvN2n2zE/g5sLCP8i8CCyTtX14QETuAbwMfHLnq1dw8YFVEPAX8gKx7reR1km4B7gP+MyLua0QFh2OAz6TUdfN84LmS5tW1coMUEY8ArwQWAduAyySdSvb/6Z35MYZ57L3Hvh3ozdt3G1nvQV046DMXRMQhZHu335Y0rtEVqrHDyf6wIAv2UyXdQ3aF82HKhpluNk+R/fR9laSPlxdGxINk/Z//2Mf6nyf7knjuiNVw8DaQBcQeJL2cbE/92vxzmceeX8A35n3BLwPeL2l2Heo6Evr9TPIhVP4beH09KzUUEbE7Im6IiHOBM4B3RMQW4B6yYwzv4JkdqqLLyH7d1K3bBhz0e4iIHwDdQDI3SJH0DrKhJ7okHQI8NyImRcS0iJgGfIr852aziYhHyQ56nSKp0p7954D3UeEK7/wK7Mvp+xdBI1wHjJV0emmGpFcBXwCWlj6TiDgQmCRpj0GqIuJOss/ro/WsdK0M9JnkB6tfC9xdqbxZSDqkbOdoNlAaiLELuAC4OyJ6Kqx+JfAZ6jwUzGgL+udI6ik8zqqwzDLgrFY4xYu+27O4dHol8G7gbyJiG9le4pVlr/HvNG/3TSkc5gLnSDqhrOx+svaM7WP1z5KNINgUIrs68UTg2Pz0yg1kXYVHs/fnciWVv4C/Crxe0vQRrOpIqvSZlProbyX70r6w7rUanH2Bb+Wnx95CdrbQ0rzs+8BL2fMg7NMi4uGI+HR+b4+68ZWxZmaJa4W9VjMzGwYHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXu/wF1XpP7Gezx3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "# load dataset\n",
    "filename = 'datasets_diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter = 4000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example also provides a box and whisker plot showing the spread of the accuracy scores\n",
    "across each cross validation fold for each algorithm.Let's use another method Area Under ROC Curve for accuracy measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.829452 (0.046997)\n",
      "LDA: 0.830384 (0.046524)\n",
      "KNN: 0.725372 (0.062930)\n",
      "CART: 0.647343 (0.050468)\n",
      "NB: 0.812392 (0.049165)\n",
      "SVM: 0.814956 (0.043043)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter = 4000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'roc_auc'\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the AUC is relatively close to 1 in LR, LDA and SVM and greater than 0.5, suggesting some skill in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset\n",
    "from pandas import read_csv\n",
    "filename = 'datasets_diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
